<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <!-- Please delete this script if you use this HTML. -->
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-MVZEHLY393"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-MVZEHLY393');
    </script>
    <meta name="viewport" content="width=500">
    <link href="stylesheet.css" rel="stylesheet" type="text/css">
    <link rel="icon" type="image/png" href="images/favicon.png">
    <title>Wen Jiang</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
          type='text/css'>
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
        <td>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width="67%" valign="middle">
                        <p align="center">
                            <name>Wen Jiang</name>
                        </p>

                        <p>Hey! I am a PhD candidate at the department of <a href="http://cis.upenn.edu/">Computer
                            and Information Science</a> at the <a href="http://www.upenn.edu/">University of
                            Pennsylvania</a> and my advisor is Prof. <a href="http://www.cis.upenn.edu/~kostas">Kostas
                            Daniilidis</a>. Before that, I got my bachelor's degree at <a
                                href="http://www.zju.edu.cn/english/">Zhejiang University</a>,
                            where I worked with Prof. <a href="http://xzhou.me/">Xiaowei Zhou</a>.
                            I was fortunate to work as a Machine Learning Intern at the 3D Vision Team for Apple Maps, a Research Scientist Intern at Meta Reality Lab, and a Visiting Fellow at Microsoft Research Asia. 
                        </p>
                        <p align=center>
                            <a href="mailto:wenjiang@seas.upenn.edu">Email</a> &nbsp/&nbsp
                            <!--<a href="data/WenJiang-CV.pdf">CV</a> &nbsp/&nbsp-->
                            <!--<a href="data/WenJiang-bio.txt">Biography</a> &nbsp/&nbsp-->
                            <a href="https://scholar.google.com/citations?user=WOB5AusAAAAJ&hl=en&oi=sra">Google
                                Scholar</a>
                            &nbsp/&nbsp
                            <a href="https://github.com/JiangWenPL">GitHub</a>&nbsp/&nbsp
                            <a href="https://www.linkedin.com/in/wen-jiang-058514125/"> LinkedIn </a>
                        </p>
                    </td>
                    <td style="padding:2.5%;width:40%;max-width:40%">
                        <a href="images/WenJiang-profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                                                                   src="images/WenJiang-circle.jpg"
                                                                   class="hoverZoomLink"></a>
                    </td>
                </tr>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width="100%" valign="middle">
                        <heading>Research</heading>
                        <p>
                            <!--<span class="highlight">More papers are under clearing and will be coming soon!</span>.-->
                        </p>
                    </td>
                </tr>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                    <tr>
                        <td width="25%">
                            <img src='images/AG-SLAM-teaser.png', width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <a href="https://arxiv.org/abs/2410.17422">
                                <papertitle>AG-SLAM: Active Gaussian Splatting SLAM</papertitle>
                            </a>
                            <br>
                            <strong>Wen Jiang</strong>*,&nbsp;
                            <a href="https://scholar.google.com/citations?user=grdM_0IAAAAJ&hl=en">Boshu Lei</a>*,&nbsp;
                            <a href="https://scholar.google.com/citations?user=_Vld-EIAAAAJ&hl=en">Katrina Ashton</a>,&nbsp;
                            <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>,&nbsp;
                            <br>
                            arxiv preprint, 2024
                            <br>
                            <a href="https://arxiv.org/abs/2410.17422">arxiv</a>
                            /
                            <a>code(comming)</a>
                            <p></p>
                            <p>An active Gaussian Splatting SLAM system with active exploration strategy, more accurate mapping and localization</p>
                        </td>
                    </tr>
                    <tr>
                        <td width="25%">
                            <img src='images/splash_next_best.png', width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <a href="https://arxiv.org/abs/2410.04680">
                                <papertitle>Next Best Sense: Guiding Vision and Touch with FisherRF for 3D Gaussian Splatting</papertitle>
                            </a>
                            <br>
                            <a href="https://peasant98.github.io/">Matthew Strong</a>*,&nbsp;
                            <a href="https://scholar.google.com/citations?user=grdM_0IAAAAJ&hl=en">Boshu Lei</a>*,&nbsp;
                            <a href="https://aidenswann.com/">Aiden Swann</a>,&nbsp;
                            <strong>Wen Jiang</strong>,&nbsp;
                            <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>,&nbsp;
                            <a href="https://monroekennedy3.com/">Monroe Kennedy III</a>
                            <br>
                            arxiv preprint, 2024
                            <br>
                            <a href="https://arm.stanford.edu/next-best-sense">Project Page</a>
                            <a href="https://arxiv.org/abs/2410.04680">arxiv</a>
                            /
                            <a href="https://github.com/armlabstanford/NextBestSense">code</a>
                            /
                            <a href="https://www.youtube.com/watch?v=NHgb_16-Plg">video</a>
                            <p></p>
                            <p>We propose a framework for active next best view and touch selection for robotic manipulators using 3D Gaussian Splatting (3DGS)</p>
                        </td>
                    </tr>
                    <tr>
                        <td width="25%">
                            <img src='images/beyond-risk.gif', width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <a href="https://arxiv.org/abs/2403.11396">
                                <papertitle>Beyond Uncertainty: Risk-Aware Active View Acquisition for Safe Robot Navigation and 3D Scene Understanding with FisherRF</papertitle>
                            </a>
                            <br>
                            <a href="https://sites.google.com/lehigh.edu/gul">Guangyi Liu</a>*,&nbsp;
                            <strong>Wen Jiang</strong>*,&nbsp;
                            <a href="https://scholar.google.com/citations?user=grdM_0IAAAAJ&hl=en">Boshu Lei</a>*,&nbsp;
                            <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>,&nbsp;
                            <a href="https://engineering.lehigh.edu/faculty/nader-motee">Nader Motee</a>
                            <br>
                            arxiv preprint, 2024
                            <br>
                            <a href="https://arxiv.org/abs/2403.11396">arxiv</a>
                            /
                            <a href="data/Liu2024BeyondRisk.bib">Bibtex</a>
                            <p></p>
                            <p>We introduce a novel approach to enhance robot navigation safety and improve 3D scene understanding by extending beyond conventional uncertainty-based methods. </p>
                        </td>
                    </tr>
                    <tr>
                        <td width="25%">
                            <img src='images/FisherRF-cropped.gif', width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <a href="https://jiangwenpl.github.io/FisherRF/">
                                <papertitle>FisherRF: Active View Selection and Uncertainty Quantification for Radiance Fields using Fisher Informations</papertitle>
                            </a>
                            <br>
                            <strong>Wen Jiang</strong>,&nbsp
                            <a href="https://scholar.google.com/citations?user=grdM_0IAAAAJ&hl=en">Boshu Lei</a>,&nbsp;
                            <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>
                            <br>
                            ECCV Oral, 2024
                            <br>
                           <a href="https://jiangwenpl.github.io/FisherRF">Project Page</a>
                           /
                            <a href="https://arxiv.org/abs/2311.17874">arxiv</a>
                            <!--<a href="">supplementary</a>-->
                            /
                            <a href="https://github.com/JiangWenPL/FisherRF">Code</a>
                            /
                            <a href="data/Jiang2023FisherRF.bib">Bibtex</a>
                            <p></p>
                            <p>FisherRF compute the Fihser Information for 3D Gaussian Splatting and other Radiance Fields and could select next best views or quantify pixel-wise uncertainty for its renderings.</p>
                        </td>
                    </tr>
                    <tr>
                        <td width="25%">
                            <img src='images/ev-decompressed.gif', width="100%">
                        </td>
                        <td valign="top" width="75%">
                            <a href="https://www.cis.upenn.edu/~ziyunw/continuity_cam/">
                                <papertitle>Event-based Continuous Color Video Decompression from Single Frames</papertitle>
                            </a>
                            <br>
                            <a href="https://scholar.google.com/citations?user=Wq7iaonvhawC&hl=en">Ziyun Wang</a>,&nbsp;
                            <a href="https://friedhelmhamann.github.io/">Friedhelm Hamann</a>,&nbsp;
                            <a href="https://scholar.google.com/citations?user=sIsVwNAAAAAJ&hl=en">Kenneth Chaney</a>,&nbsp;
                            <strong>Wen Jiang</strong>,&nbsp
                            <a href="https://sites.google.com/view/guillermogallego">Guillermo Gallego</a>,&nbsp;
                            <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>
                            <br>
                            arxiv preprint, 2023
                            <br>
                           <a href="https://www.cis.upenn.edu/~ziyunw/continuity_cam/">Project Page</a>
                           /
                            <a href="https://arxiv.org/abs/2312.00113">arxiv</a>
                            /
                            <a href="https://arxiv.org/pdf/2312.00113.pdf">Paper</a>
                            /
                            <a href="data/Wang2023video.bib">Bibtex</a>
                            <p></p>
                            <p>We propose a novel task called event-based continuous color video decompression , pairing single static color frames and events to reconstruct temporally continuous videos.</p>
                        </td>
                    </tr>
                <tr onmouseout="probshape_stop()" onmouseover="probshape_start()">
                    <td width="25%">
                        <img src='images/prob_shape_teaser_net_160x160.jpg'>
                    </td>
                    <td valign="top" width="75%">
                        <a href="https://arxiv.org/abs/2212.03370">
                            <papertitle>Probabilistic Shape Completion by Estimating Canonical Factors with Hierarchical VAE</papertitle>
                        </a>
                        <br>
                        <strong>Wen Jiang</strong>,&nbsp
                        <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>
                        <br>
                        arxiv preprint, 2022
                        <br>
                        <a href="https://arxiv.org/abs/2212.03370">arxiv</a>
                        <!--<a href="">supplementary</a>-->
                        /
                        <a >Code(coming soon)</a>
                        /
                        <a href="data/Jiang2020MPShape.bib">Bibtex</a>
                        <p></p>
                        <p>We propose a novel method for 3D shape completion from a partial observation of a point cloud.</p>
                    </td>
                </tr>
                <tr onmouseout="tmvpose_stop()" onmouseover="tmvpose_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <div class="two" id="tmvpose_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
                                <source src="images/tmvpose_resize.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                            </video></div>
                            <img src="images/tmvpose.jpg" width="160">
                        </div>
                        <script type="text/javascript">
                            function tmvpose_start() {
                                document.getElementById('tmvpose_image').style.opacity = "1";
                            }

                            function tmvpose_stop() {
                                document.getElementById('tmvpose_image').style.opacity = "0";
                            }
                            tmvpose_stop()
                        </script>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <a href="https://ieeexplore.ieee.org/document/9492024">
                            <papertitle>Fast and Robust Multi-Person 3D Pose Estimation and Tracking from Multiple Views</papertitle>
                        </a>
                        <br>
                        <a href="http://jtdong.com/">Junting Dong</a>,&nbsp
                        <a href="https://raypine.github.io/"> Qi Fang</a>,&nbsp
                        <strong>Wen Jiang</strong>,&nbsp
                        <a href="https://www.ri.cmu.edu/ri-people/yurou-yang/"> Yurou Yang</a>,&nbsp
                        <a href="https://www.cs.utexas.edu/~huangqx/">Qixing Huang</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/xzhou/">Xiaowei Zhou</a>
                        <br>
                        <em>T-PAMI</em>, 2021
                        <br>
                        <a href="https://zju3dv.github.io/mvpose/">Project page</a> /
                        <a href="https://zju3dv.github.io/mvpose/egpaper_supplementary.pdf">Supplementary</a> /
                        <a href="https://github.com/zju3dv/mvpose">Code</a> /
                        <a href="data/tmvpose.bib">Bibtex</a>
                        <p></p>
                        <!--              <p>Extend the Mvpose with temporal tracking and filtering.</p>-->
                    </td>
                </tr>
                <tr onmouseout="multiperson_stop()" onmouseover="multiperson_start()">
                    <td valign="top" align="center" width="10%">
                        <div class="one">
                            <div class="two" id="multiperson_image" style="opacity: 0;"><img width="100%"
                                                                                             src="images/multiperson_teaser.gif">
                            </div>
                            <img width="100%" src="images/multiperson_teaser.png">
                        </div>
                        <script type="text/javascript">
                            function multiperson_start() {
                                document.getElementById('multiperson_image').style.opacity = "1";
                            }

                            function multiperson_stop() {
                                document.getElementById('multiperson_image').style.opacity = "0";
                            }

                            multiperson_stop()
                        </script>
                    </td>
                    <td valign="top" width="75%">
                        <a href="https://jiangwenpl.github.io/multiperson/">
                            <papertitle>Coherent Reconstruction of Multiple Humans from a Single Image</papertitle>
                        </a>
                        <br>
                        <strong>Wen Jiang</strong>*, &nbsp
                        <a href="https://www.seas.upenn.edu/~nkolot/">Nikos Kolotouros</a>*, &nbsp
                        <a href="https://seas.upenn.edu/~pavlakos">Georgios Pavlakos</a>, &nbsp
                        <a href="http://www.cad.zju.edu.cn/home/xzhou">Xiaowei Zhou</a>, &nbsp
                        <a href="https://cis.upenn.edu/~kostas">Kostas Daniilidis</a>
                        <br>
                        <em>CVPR</em>, 2020 &nbsp
                        <br>
                        <a href="https://jiangwenpl.github.io/multiperson/">Project Page</a>
                        /
                        <a href="http://arxiv.org/abs/2006.08586">Paper</a>
                        <!--<a href="">supplementary</a>-->
                        /
                        <a href="https://github.com/JiangWenPL/multiperson">Code</a>
                        /
                        <a href="data/Jiang2020MPShape.bib">Bibtex</a>
                        <p></p>
                        <p>End-to-end reconstruction of multiple people using two novel geometric losses that encourage
                            coherent 3D estimates</p>
                    </td>
                </tr>
                <tr onmouseout="snake_stop()" onmouseover="snake_start()">
                    <td width="25%">
                        <img src='images/snake.png'>
                    </td>
                    <td valign="middle" width="75%">
                        <a href="https://arxiv.org/abs/2001.01629">
                            <papertitle>Deep Snake for Real-Time Instance Segmentation</papertitle>
                        </a>
                        <br>
                        <a href="https://pengsida.net">Sida Peng</a>,&nbsp
                        <strong>Wen Jiang</strong>,&nbsp
                        <a>Huaijin Pi</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/xzhou/">Xiaowei Zhou</a>
                        <br>
                        <em>CVPR</em>, 2020 Oral presentation&nbsp
                        <br>
                        <a href="https://arxiv.org/abs/2001.01629">Arxiv</a> /
                        <a href="https://github.com/zju3dv/snake">Code</a> /
                        <a href="data/Peng2020.bib">Bibtex</a>
                        <p></p>
                        <p>This paper introduces a novel contour-based approach named deep snake for real-time
                            instance
                            segmentation.</p>
                    </td>
                </tr>
<!--                <tr onmouseout="mvpose_stop()" onmouseover="mvpose_start()" bgcolor="#ffffd0">-->
                <tr onmouseout="mvpose_stop()" onmouseover="mvpose_start()">
                    <td width="25%">
                        <img src='images/mvpose.jpg'>
                    </td>
                    <td valign="middle" width="75%">
                        <a href="https://zju3dv.github.io/mvpose/">
                            <papertitle>Fast and Robust Multi-Person 3D Pose Estimation from Multiple Views
                            </papertitle>
                        </a>
                        <br>
                        <a href="http://jtdong.com/">Junting Dong</a>,&nbsp
                        <strong>Wen Jiang</strong>,&nbsp
                        <a href="https://www.cs.utexas.edu/~huangqx/">Qixing Huang</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>,&nbsp
                        <a href="http://www.cad.zju.edu.cn/home/xzhou/">Xiaowei Zhou</a>
                        <br>
                        <em>CVPR</em>, 2019 &nbsp
                        <br>
                        <a href="https://zju3dv.github.io/mvpose/">Project page</a> /
                        <a href="https://arxiv.org/abs/1901.04111">Arxiv</a> /
                        <a href="https://zju3dv.github.io/mvpose/supplymentary.html">Supplement</a> /
                        <a href="https://youtu.be/axSRz6G98gE">Video</a> /
                        <a href="https://github.com/zju-3dv/multi-person3dpose">Code</a> /
                        <a href="data/DongCVPR2019.bib">Bibtex</a>
                        <p></p>
                        <p>This paper addresses the problem of 3D pose estimation for multiple people in a few
                            calibrated camera views.</p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td width="100%" valign="middle">
                        <heading>Miscellaneous</heading>
                    </td>
                </tr>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="25%">
                        <img src='images/cvf.jpg'>
                    </td>
                    <td valign="middle" width="75%">
                        <a >
                            Reviewer
                        </a>
                        <br>
                        <a href="https://cvpr2022.thecvf.com/">CVPR2022-2023</a>, <a, href="https://iccv2023.thecvf.com/">ICCV2023</a>, <a>ECCV 2022</a>, <a>T-PAMI</a>, <a>3DV 2022</a>
                        <p></p>
                    </td>
                </tr>
                <tr>
                    <td width="25%">
                        <img src='images/favicon.png' height=150 width=150>
                    </td>
                    <td valign="middle" width="75%">
                        <a >
                            Teaching Assistant
                        </a>
                        <br>
                        <a href="https://sites.google.com/seas.upenn.edu/cis580spr22/home">CIS 580: Machine Perception</a>
                        <br>
                        <a href="https://catalog.upenn.edu/courses/cis/">CIS 680: Advanced Topics in Machine Perception</a>
                        <p></p>
                    </td>
                </tr>
                </tbody>
            </table>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td>
                        <br>
                        <p align="right"><font size="1">
                            <a href="http://jonbarron.info/">This guy has an awesome website</a>
                        </font>
                        </p>
                    </td>

                </tr>
            </table>
        </td>
    </tr>
</table>
</body>

</html>
